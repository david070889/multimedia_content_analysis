{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdcd4f5-77ab-4f8d-a1a2-e2b951855355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料增強與標準化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f0ebe9-443d-41fa-9354-56952aecfeab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加載數據\n",
    "train_dataset = datasets.ImageFolder(root='../dataloader_c23/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='../dataloader_c23/validation', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataloader_c23/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d518f5f1-cd5e-4b4f-9047-805b32c344f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "# 創建模型，預訓練且將分類層設置為2類\n",
    "model = timm.create_model('efficientformerv2_s0', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "model.head_dist = nn.Linear(model.head_dist.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d96fa561-d115-45e0-a08b-182d6022c88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "def train(epoch, epochs, model, train_loader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    \n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # 確保數據在正確的設備上\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # 模型輸出\n",
    "        loss = loss_function(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 計算準確率\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    running_loss = running_loss / train_steps\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8af3c20-c988-44c8-9a71-0224393ae25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 驗證函數\n",
    "def validate(epoch, epochs, model, validate_loader, loss_function, device):\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_num = len(validate_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            outputs = model(val_images)\n",
    "            loss = loss_function(outputs, val_labels)\n",
    "            val_loss += loss.item() * val_images.size(0)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "    \n",
    "    val_loss /= val_num\n",
    "    val_accurate = acc / val_num\n",
    "    return val_loss, val_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ea082e-b70c-4744-88ca-a5072b4d0e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/25] loss:0.126: 100%|██████████| 282/282 [02:46<00:00,  1.69it/s]\n",
      "valid epoch[1/25]: 100%|██████████| 55/55 [00:27<00:00,  2.02it/s]\n",
      "[epoch 1] train_loss: 0.461  train_accuracy: 76.817\n",
      "[epoch 1] val_loss: 0.477  val_accuracy: 0.808\n",
      "Training_Time: 193.88 seconds\n",
      "train epoch[2/25] loss:0.286: 100%|██████████| 282/282 [02:14<00:00,  2.09it/s]\n",
      "valid epoch[2/25]: 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n",
      "[epoch 2] train_loss: 0.184  train_accuracy: 92.636\n",
      "[epoch 2] val_loss: 0.810  val_accuracy: 0.733\n",
      "Training_Time: 157.82 seconds\n",
      "train epoch[3/25] loss:0.185: 100%|██████████| 282/282 [02:13<00:00,  2.11it/s]\n",
      "valid epoch[3/25]: 100%|██████████| 55/55 [00:22<00:00,  2.49it/s]\n",
      "[epoch 3] train_loss: 0.110  train_accuracy: 95.688\n",
      "[epoch 3] val_loss: 0.409  val_accuracy: 0.859\n",
      "Training_Time: 155.73 seconds\n",
      "train epoch[4/25] loss:0.150: 100%|██████████| 282/282 [02:13<00:00,  2.11it/s]\n",
      "valid epoch[4/25]: 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n",
      "[epoch 4] train_loss: 0.077  train_accuracy: 97.104\n",
      "[epoch 4] val_loss: 0.454  val_accuracy: 0.859\n",
      "Training_Time: 156.87 seconds\n",
      "train epoch[5/25] loss:0.139: 100%|██████████| 282/282 [02:13<00:00,  2.12it/s]\n",
      "valid epoch[5/25]: 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n",
      "[epoch 5] train_loss: 0.060  train_accuracy: 97.743\n",
      "[epoch 5] val_loss: 0.769  val_accuracy: 0.825\n",
      "Training_Time: 155.96 seconds\n",
      "train epoch[6/25] loss:0.034: 100%|██████████| 282/282 [02:13<00:00,  2.11it/s]\n",
      "valid epoch[6/25]: 100%|██████████| 55/55 [00:22<00:00,  2.39it/s]\n",
      "[epoch 6] train_loss: 0.054  train_accuracy: 97.960\n",
      "[epoch 6] val_loss: 0.520  val_accuracy: 0.859\n",
      "Training_Time: 156.78 seconds\n",
      "train epoch[7/25] loss:0.121: 100%|██████████| 282/282 [02:14<00:00,  2.10it/s]\n",
      "valid epoch[7/25]: 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n",
      "[epoch 7] train_loss: 0.042  train_accuracy: 98.419\n",
      "[epoch 7] val_loss: 0.510  val_accuracy: 0.857\n",
      "Training_Time: 157.27 seconds\n",
      "train epoch[8/25] loss:0.019: 100%|██████████| 282/282 [02:16<00:00,  2.07it/s]\n",
      "valid epoch[8/25]: 100%|██████████| 55/55 [00:22<00:00,  2.42it/s]\n",
      "[epoch 8] train_loss: 0.041  train_accuracy: 98.474\n",
      "[epoch 8] val_loss: 0.599  val_accuracy: 0.851\n",
      "Training_Time: 159.12 seconds\n",
      "train epoch[9/25] loss:0.006: 100%|██████████| 282/282 [02:14<00:00,  2.09it/s]\n",
      "valid epoch[9/25]: 100%|██████████| 55/55 [00:22<00:00,  2.41it/s]\n",
      "[epoch 9] train_loss: 0.033  train_accuracy: 98.728\n",
      "[epoch 9] val_loss: 0.568  val_accuracy: 0.864\n",
      "Training_Time: 157.73 seconds\n",
      "train epoch[10/25] loss:0.013: 100%|██████████| 282/282 [02:15<00:00,  2.08it/s]\n",
      "valid epoch[10/25]: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
      "[epoch 10] train_loss: 0.034  train_accuracy: 98.736\n",
      "[epoch 10] val_loss: 0.690  val_accuracy: 0.833\n",
      "Training_Time: 159.24 seconds\n",
      "train epoch[11/25] loss:0.023: 100%|██████████| 282/282 [02:25<00:00,  1.94it/s]\n",
      "valid epoch[11/25]: 100%|██████████| 55/55 [00:26<00:00,  2.11it/s]\n",
      "[epoch 11] train_loss: 0.032  train_accuracy: 98.786\n",
      "[epoch 11] val_loss: 0.516  val_accuracy: 0.874\n",
      "Training_Time: 171.30 seconds\n",
      "train epoch[12/25] loss:0.137: 100%|██████████| 282/282 [02:20<00:00,  2.00it/s]\n",
      "valid epoch[12/25]: 100%|██████████| 55/55 [00:23<00:00,  2.30it/s]\n",
      "[epoch 12] train_loss: 0.031  train_accuracy: 98.879\n",
      "[epoch 12] val_loss: 0.749  val_accuracy: 0.830\n",
      "Training_Time: 164.62 seconds\n",
      "train epoch[13/25] loss:0.012: 100%|██████████| 282/282 [02:17<00:00,  2.06it/s]\n",
      "valid epoch[13/25]: 100%|██████████| 55/55 [00:24<00:00,  2.26it/s]\n",
      "[epoch 13] train_loss: 0.030  train_accuracy: 98.911\n",
      "[epoch 13] val_loss: 0.699  val_accuracy: 0.849\n",
      "Training_Time: 161.47 seconds\n",
      "train epoch[14/25] loss:0.091: 100%|██████████| 282/282 [02:17<00:00,  2.06it/s]\n",
      "valid epoch[14/25]: 100%|██████████| 55/55 [00:24<00:00,  2.24it/s]\n",
      "[epoch 14] train_loss: 0.027  train_accuracy: 99.003\n",
      "[epoch 14] val_loss: 0.544  val_accuracy: 0.871\n",
      "Training_Time: 161.79 seconds\n",
      "train epoch[15/25] loss:0.105: 100%|██████████| 282/282 [02:18<00:00,  2.03it/s]\n",
      "valid epoch[15/25]: 100%|██████████| 55/55 [00:25<00:00,  2.19it/s]\n",
      "[epoch 15] train_loss: 0.025  train_accuracy: 99.115\n",
      "[epoch 15] val_loss: 0.607  val_accuracy: 0.863\n",
      "Training_Time: 163.80 seconds\n",
      "train epoch[16/25] loss:0.021: 100%|██████████| 282/282 [02:20<00:00,  2.01it/s]\n",
      "valid epoch[16/25]: 100%|██████████| 55/55 [00:26<00:00,  2.11it/s]\n",
      "[epoch 16] train_loss: 0.028  train_accuracy: 99.011\n",
      "[epoch 16] val_loss: 0.857  val_accuracy: 0.824\n",
      "Training_Time: 166.33 seconds\n",
      "train epoch[17/25] loss:0.033: 100%|██████████| 282/282 [02:19<00:00,  2.01it/s]\n",
      "valid epoch[17/25]: 100%|██████████| 55/55 [00:25<00:00,  2.15it/s]\n",
      "[epoch 17] train_loss: 0.024  train_accuracy: 99.106\n",
      "[epoch 17] val_loss: 0.609  val_accuracy: 0.877\n",
      "Training_Time: 165.61 seconds\n",
      "train epoch[18/25] loss:0.019: 100%|██████████| 282/282 [02:20<00:00,  2.00it/s]\n",
      "valid epoch[18/25]: 100%|██████████| 55/55 [00:25<00:00,  2.16it/s]\n",
      "[epoch 18] train_loss: 0.023  train_accuracy: 99.176\n",
      "[epoch 18] val_loss: 0.709  val_accuracy: 0.853\n",
      "Training_Time: 166.15 seconds\n",
      "train epoch[19/25] loss:0.026: 100%|██████████| 282/282 [02:19<00:00,  2.03it/s]\n",
      "valid epoch[19/25]: 100%|██████████| 55/55 [00:23<00:00,  2.31it/s]\n",
      "[epoch 19] train_loss: 0.023  train_accuracy: 99.162\n",
      "[epoch 19] val_loss: 0.581  val_accuracy: 0.877\n",
      "Training_Time: 163.01 seconds\n",
      "train epoch[20/25] loss:0.034: 100%|██████████| 282/282 [02:12<00:00,  2.13it/s]\n",
      "valid epoch[20/25]: 100%|██████████| 55/55 [00:23<00:00,  2.36it/s]\n",
      "[epoch 20] train_loss: 0.023  train_accuracy: 99.154\n",
      "[epoch 20] val_loss: 0.866  val_accuracy: 0.846\n",
      "Training_Time: 155.87 seconds\n",
      "train epoch[21/25] loss:0.022: 100%|██████████| 282/282 [02:13<00:00,  2.12it/s]\n",
      "valid epoch[21/25]: 100%|██████████| 55/55 [00:23<00:00,  2.33it/s]\n",
      "[epoch 21] train_loss: 0.019  train_accuracy: 99.304\n",
      "[epoch 21] val_loss: 0.664  val_accuracy: 0.865\n",
      "Training_Time: 156.77 seconds\n",
      "train epoch[22/25] loss:0.002: 100%|██████████| 282/282 [02:12<00:00,  2.13it/s]\n",
      "valid epoch[22/25]: 100%|██████████| 55/55 [00:23<00:00,  2.37it/s]\n",
      "[epoch 22] train_loss: 0.021  train_accuracy: 99.240\n",
      "[epoch 22] val_loss: 0.946  val_accuracy: 0.806\n",
      "Training_Time: 155.95 seconds\n",
      "train epoch[23/25] loss:0.002: 100%|██████████| 282/282 [02:13<00:00,  2.12it/s]\n",
      "valid epoch[23/25]: 100%|██████████| 55/55 [00:24<00:00,  2.20it/s]\n",
      "[epoch 23] train_loss: 0.019  train_accuracy: 99.335\n",
      "[epoch 23] val_loss: 0.616  val_accuracy: 0.872\n",
      "Training_Time: 158.12 seconds\n",
      "train epoch[24/25] loss:0.010: 100%|██████████| 282/282 [02:26<00:00,  1.92it/s]\n",
      "valid epoch[24/25]: 100%|██████████| 55/55 [00:25<00:00,  2.18it/s]\n",
      "[epoch 24] train_loss: 0.019  train_accuracy: 99.356\n",
      "[epoch 24] val_loss: 0.623  val_accuracy: 0.872\n",
      "Training_Time: 172.12 seconds\n",
      "train epoch[25/25] loss:0.010: 100%|██████████| 282/282 [02:25<00:00,  1.94it/s]\n",
      "valid epoch[25/25]: 100%|██████████| 55/55 [00:23<00:00,  2.34it/s]\n",
      "[epoch 25] train_loss: 0.022  train_accuracy: 99.213\n",
      "[epoch 25] val_loss: 0.636  val_accuracy: 0.871\n",
      "Training_Time: 168.56 seconds\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# 訓練和驗證模型\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "save_path = 'best_mobilenetV4_s.pth'\n",
    "t_l, t_a = [], []\n",
    "v_l, v_a = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_accuracy = train(epoch, num_epochs, model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accurate = validate(epoch, num_epochs, model, val_loader, criterion, device)\n",
    "    t_l.append(train_loss)\n",
    "    t_a.append(train_accuracy)\n",
    "    v_l.append(val_loss)\n",
    "    v_a.append(val_accurate)\n",
    "    \n",
    "    print('[epoch %d] train_loss: %.3f  train_accuracy: %.3f' %\n",
    "            (epoch + 1, train_loss, train_accuracy))\n",
    "    print('[epoch %d] val_loss: %.3f  val_accuracy: %.3f' %\n",
    "            (epoch + 1, val_loss, val_accurate))\n",
    "    \n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    end_time = time.time()\n",
    "    print(f'Training_Time: {end_time - start_time:.2f} seconds')\n",
    "    \n",
    "print('訓練完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7b35d73-6a96-49b2-811e-5b5b868df8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_efficientformerV2_s0.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2028aa4-ec3e-464b-adc2-556cbb9f9c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metrics_to_file(t_l, t_a, v_l, v_a, filename='metrics.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Train Loss:\\n\")\n",
    "        for item in t_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Train Accuracy:\\n\")\n",
    "        for item in t_a:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Loss:\\n\")\n",
    "        for item in v_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Accuracy:\\n\")\n",
    "        for item in v_a:\n",
    "            file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc5915e-74f9-4664-a0a3-1f0c9655bd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 假設 t_l, t_a, v_l, v_a 已經被填充\n",
    "filename = 'efficientformerV2_s0.txt'\n",
    "save_metrics_to_file(t_l, t_a, v_l, v_a, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262b62f-4de2-49d4-b654-b17cb184c5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 確認設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 創建模型，預訓練且將分類層設置為2類\n",
    "model = timm.create_model('efficientformerv2_s0', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "model.head_dist = nn.Linear(model.head_dist.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# 打印模型結構以確認最後一層\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2560d02e-55db-45a0-923e-e51ac1297ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc of Celeb DF V2: 0.7100\n"
     ]
    }
   ],
   "source": [
    "test_celeb_dataset = datasets.ImageFolder(root='../CelebDF_v2/extracted_frames', transform=transform)\n",
    "celeb_loader = DataLoader(test_celeb_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_efficientformerV2_s0.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in celeb_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc of Celeb DF V2: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb9e2179-1881-443c-99bb-34c1dd6333b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用 TorchScript 將模型保存為 .pt 文件\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "# 加載預訓練的 MobileNetV3 大模型\n",
    "model = timm.create_model('efficientformerv2_s0', pretrained=False)\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "model.head_dist = nn.Linear(model.head_dist.in_features, 2)\n",
    "model.load_state_dict(torch.load('best_efficientformerV2_s0.pth'))\n",
    "model.eval()\n",
    "\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example_input)\n",
    "torch.jit.save(traced_script_module, 'efficientformerV2_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a02d50-a2ec-4c49-b15b-508e348033b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
