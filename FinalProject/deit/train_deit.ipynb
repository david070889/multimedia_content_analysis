{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19792b91-6b08-4189-b94d-8ee6c71139ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料增強與標準化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584b44cf-c70d-4c63-9830-9b1e9a546dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加載數據\n",
    "train_dataset = datasets.ImageFolder(root='../dataloader_c23/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='../dataloader_c23/validation', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataloader_c23/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddcf0548-ad37-4be4-a631-18777f4ee88d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "# 創建模型，預訓練且將分類層設置為2類\n",
    "model = timm.create_model('deit_tiny_distilled_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "model.head_dist = nn.Linear(model.head_dist.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbdac6d0-0645-4b3c-ab12-c0453995805c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "def train(epoch, epochs, model, train_loader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    \n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # 確保數據在正確的設備上\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # 模型輸出\n",
    "        loss = loss_function(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 計算準確率\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    running_loss = running_loss / train_steps\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41845a2-f456-4d61-a079-23bd2fae31e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 驗證函數\n",
    "def validate(epoch, epochs, model, validate_loader, loss_function, device):\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_num = len(validate_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            outputs = model(val_images)\n",
    "            loss = loss_function(outputs, val_labels)\n",
    "            val_loss += loss.item() * val_images.size(0)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "    \n",
    "    val_loss /= val_num\n",
    "    val_accurate = acc / val_num\n",
    "    return val_loss, val_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c4fd0c-3934-4c1d-a338-017be75f3ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/25] loss:0.682: 100%|██████████| 282/282 [39:10<00:00,  8.33s/it]\n",
      "valid epoch[1/25]: 100%|██████████| 55/55 [00:19<00:00,  2.80it/s]\n",
      "[epoch 1] train_loss: 0.714  train_accuracy: 50.633\n",
      "[epoch 1] val_loss: 0.692  val_accuracy: 0.507\n",
      "Training_Time: 2370.06 seconds\n",
      "train epoch[2/25] loss:0.655: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[2/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 2] train_loss: 0.683  train_accuracy: 55.846\n",
      "[epoch 2] val_loss: 0.683  val_accuracy: 0.562\n",
      "Training_Time: 2340.24 seconds\n",
      "train epoch[3/25] loss:0.688: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[3/25]: 100%|██████████| 55/55 [00:20<00:00,  2.65it/s]\n",
      "[epoch 3] train_loss: 0.665  train_accuracy: 59.619\n",
      "[epoch 3] val_loss: 0.700  val_accuracy: 0.581\n",
      "Training_Time: 2341.45 seconds\n",
      "train epoch[4/25] loss:0.757: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[4/25]: 100%|██████████| 55/55 [00:19<00:00,  2.75it/s]\n",
      "[epoch 4] train_loss: 0.650  train_accuracy: 61.767\n",
      "[epoch 4] val_loss: 0.668  val_accuracy: 0.592\n",
      "Training_Time: 2340.49 seconds\n",
      "train epoch[5/25] loss:0.666: 100%|██████████| 282/282 [38:41<00:00,  8.23s/it]\n",
      "valid epoch[5/25]: 100%|██████████| 55/55 [00:19<00:00,  2.79it/s]\n",
      "[epoch 5] train_loss: 0.639  train_accuracy: 63.006\n",
      "[epoch 5] val_loss: 0.658  val_accuracy: 0.610\n",
      "Training_Time: 2341.76 seconds\n",
      "train epoch[6/25] loss:0.602: 100%|██████████| 282/282 [38:41<00:00,  8.23s/it]\n",
      "valid epoch[6/25]: 100%|██████████| 55/55 [00:20<00:00,  2.65it/s]\n",
      "[epoch 6] train_loss: 0.620  train_accuracy: 64.912\n",
      "[epoch 6] val_loss: 0.670  val_accuracy: 0.612\n",
      "Training_Time: 2341.89 seconds\n",
      "train epoch[7/25] loss:0.611: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[7/25]: 100%|██████████| 55/55 [00:19<00:00,  2.78it/s]\n",
      "[epoch 7] train_loss: 0.599  train_accuracy: 66.958\n",
      "[epoch 7] val_loss: 0.686  val_accuracy: 0.626\n",
      "Training_Time: 2340.59 seconds\n",
      "train epoch[8/25] loss:0.656: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[8/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 8] train_loss: 0.579  train_accuracy: 68.524\n",
      "[epoch 8] val_loss: 0.640  val_accuracy: 0.639\n",
      "Training_Time: 2340.69 seconds\n",
      "train epoch[9/25] loss:0.434: 100%|██████████| 282/282 [38:42<00:00,  8.23s/it]\n",
      "valid epoch[9/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 9] train_loss: 0.557  train_accuracy: 70.400\n",
      "[epoch 9] val_loss: 0.674  val_accuracy: 0.659\n",
      "Training_Time: 2342.01 seconds\n",
      "train epoch[10/25] loss:0.511: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[10/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 10] train_loss: 0.533  train_accuracy: 72.399\n",
      "[epoch 10] val_loss: 0.674  val_accuracy: 0.660\n",
      "Training_Time: 2341.09 seconds\n",
      "train epoch[11/25] loss:0.479: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[11/25]: 100%|██████████| 55/55 [00:19<00:00,  2.75it/s]\n",
      "[epoch 11] train_loss: 0.508  train_accuracy: 74.206\n",
      "[epoch 11] val_loss: 0.687  val_accuracy: 0.652\n",
      "Training_Time: 2340.29 seconds\n",
      "train epoch[12/25] loss:0.453: 100%|██████████| 282/282 [38:51<00:00,  8.27s/it]\n",
      "valid epoch[12/25]: 100%|██████████| 55/55 [00:20<00:00,  2.63it/s]\n",
      "[epoch 12] train_loss: 0.485  train_accuracy: 75.754\n",
      "[epoch 12] val_loss: 0.660  val_accuracy: 0.663\n",
      "Training_Time: 2352.87 seconds\n",
      "train epoch[13/25] loss:0.374: 100%|██████████| 282/282 [38:56<00:00,  8.29s/it]\n",
      "valid epoch[13/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 13] train_loss: 0.459  train_accuracy: 77.460\n",
      "[epoch 13] val_loss: 0.706  val_accuracy: 0.661\n",
      "Training_Time: 2356.92 seconds\n",
      "train epoch[14/25] loss:0.507: 100%|██████████| 282/282 [38:40<00:00,  8.23s/it]\n",
      "valid epoch[14/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 14] train_loss: 0.430  train_accuracy: 79.393\n",
      "[epoch 14] val_loss: 0.699  val_accuracy: 0.675\n",
      "Training_Time: 2340.69 seconds\n",
      "train epoch[15/25] loss:0.390: 100%|██████████| 282/282 [38:47<00:00,  8.25s/it]\n",
      "valid epoch[15/25]: 100%|██████████| 55/55 [00:19<00:00,  2.78it/s]\n",
      "[epoch 15] train_loss: 0.404  train_accuracy: 80.994\n",
      "[epoch 15] val_loss: 0.754  val_accuracy: 0.675\n",
      "Training_Time: 2347.50 seconds\n",
      "train epoch[16/25] loss:0.349: 100%|██████████| 282/282 [42:33<00:00,  9.06s/it]\n",
      "valid epoch[16/25]: 100%|██████████| 55/55 [01:10<00:00,  1.29s/it]\n",
      "[epoch 16] train_loss: 0.373  train_accuracy: 82.747\n",
      "[epoch 16] val_loss: 0.984  val_accuracy: 0.642\n",
      "Training_Time: 2624.66 seconds\n",
      "train epoch[17/25] loss:0.246: 100%|██████████| 282/282 [43:25<00:00,  9.24s/it]\n",
      "valid epoch[17/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 17] train_loss: 0.348  train_accuracy: 83.990\n",
      "[epoch 17] val_loss: 0.889  val_accuracy: 0.670\n",
      "Training_Time: 2679.33 seconds\n",
      "train epoch[18/25] loss:0.342: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[18/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 18] train_loss: 0.323  train_accuracy: 85.571\n",
      "[epoch 18] val_loss: 0.850  val_accuracy: 0.666\n",
      "Training_Time: 2667.42 seconds\n",
      "train epoch[19/25] loss:0.218: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[19/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 19] train_loss: 0.295  train_accuracy: 87.207\n",
      "[epoch 19] val_loss: 0.790  val_accuracy: 0.672\n",
      "Training_Time: 2667.30 seconds\n",
      "train epoch[20/25] loss:0.237: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[20/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 20] train_loss: 0.272  train_accuracy: 88.157\n",
      "[epoch 20] val_loss: 1.004  val_accuracy: 0.669\n",
      "Training_Time: 2667.25 seconds\n",
      "train epoch[21/25] loss:0.228: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[21/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 21] train_loss: 0.249  train_accuracy: 89.507\n",
      "[epoch 21] val_loss: 1.051  val_accuracy: 0.672\n",
      "Training_Time: 2667.81 seconds\n",
      "train epoch[22/25] loss:0.341: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[22/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 22] train_loss: 0.224  train_accuracy: 90.449\n",
      "[epoch 22] val_loss: 1.173  val_accuracy: 0.673\n",
      "Training_Time: 2667.43 seconds\n",
      "train epoch[23/25] loss:0.214: 100%|██████████| 282/282 [46:29<00:00,  9.89s/it]\n",
      "valid epoch[23/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 23] train_loss: 0.205  train_accuracy: 91.503\n",
      "[epoch 23] val_loss: 1.285  val_accuracy: 0.664\n",
      "Training_Time: 2863.58 seconds\n",
      "train epoch[24/25] loss:0.132: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[24/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 24] train_loss: 0.185  train_accuracy: 92.388\n",
      "[epoch 24] val_loss: 1.198  val_accuracy: 0.674\n",
      "Training_Time: 2667.16 seconds\n",
      "train epoch[25/25] loss:0.150: 100%|██████████| 282/282 [43:13<00:00,  9.20s/it]\n",
      "valid epoch[25/25]: 100%|██████████| 55/55 [01:13<00:00,  1.34s/it]\n",
      "[epoch 25] train_loss: 0.165  train_accuracy: 93.314\n",
      "[epoch 25] val_loss: 1.176  val_accuracy: 0.672\n",
      "Training_Time: 2667.13 seconds\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# 訓練和驗證模型\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "save_path = 'best_deit_tiny_dis.pth'\n",
    "t_l, t_a = [], []\n",
    "v_l, v_a = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_accuracy = train(epoch, num_epochs, model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accurate = validate(epoch, num_epochs, model, val_loader, criterion, device)\n",
    "    t_l.append(train_loss)\n",
    "    t_a.append(train_accuracy)\n",
    "    v_l.append(val_loss)\n",
    "    v_a.append(val_accurate)\n",
    "    \n",
    "    print('[epoch %d] train_loss: %.3f  train_accuracy: %.3f' %\n",
    "            (epoch + 1, train_loss, train_accuracy))\n",
    "    print('[epoch %d] val_loss: %.3f  val_accuracy: %.3f' %\n",
    "            (epoch + 1, val_loss, val_accurate))\n",
    "    \n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    end_time = time.time()\n",
    "    print(f'Training_Time: {end_time - start_time:.2f} seconds')\n",
    "    \n",
    "print('訓練完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56593d72-dc74-4379-af1d-eaab072a1e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6694\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_deit_tiny_dis.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c203cdac-433e-48c9-9220-fd73666a2a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metrics_to_file(t_l, t_a, v_l, v_a, filename='metrics.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Train Loss:\\n\")\n",
    "        for item in t_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Train Accuracy:\\n\")\n",
    "        for item in t_a:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Loss:\\n\")\n",
    "        for item in v_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Accuracy:\\n\")\n",
    "        for item in v_a:\n",
    "            file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df93f6fd-791c-4eac-9257-42d41b2b6eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 假設 t_l, t_a, v_l, v_a 已經被填充\n",
    "filename = 'deit_tiny_dis.txt'\n",
    "save_metrics_to_file(t_l, t_a, v_l, v_a, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "617fd693-703a-4095-bd78-3e0237fd215c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc of Celeb DF V2: 0.7086\n"
     ]
    }
   ],
   "source": [
    "test_celeb_dataset = datasets.ImageFolder(root='../archive/extracted_frames', transform=transform)\n",
    "celeb_loader = DataLoader(test_celeb_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_deit_tiny_dis.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in celeb_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc of Celeb DF V2: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17c36e6-00dd-46cf-8cc2-215c65165c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 使用 TorchScript 將模型保存為 .pt 文件\u001b[39;00m\n\u001b[0;32m      2\u001b[0m example_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m traced_script_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mtrace(model, example_input)\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39msave(traced_script_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepvit_jit.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\jit\\_trace.py:806\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    807\u001b[0m         func,\n\u001b[0;32m    808\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    810\u001b[0m         check_trace,\n\u001b[0;32m    811\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[0;32m    812\u001b[0m         check_tolerance,\n\u001b[0;32m    813\u001b[0m         strict,\n\u001b[0;32m    814\u001b[0m         _force_outplace,\n\u001b[0;32m    815\u001b[0m         _module_class,\n\u001b[0;32m    816\u001b[0m         example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(example_kwarg_inputs, \u001b[38;5;28mdict\u001b[39m),\n\u001b[0;32m    817\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs,\n\u001b[0;32m    818\u001b[0m     )\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    823\u001b[0m ):\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\jit\\_trace.py:1074\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1073\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m-> 1074\u001b[0m     module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_create_method_from_trace(\n\u001b[0;32m   1075\u001b[0m         method_name,\n\u001b[0;32m   1076\u001b[0m         func,\n\u001b[0;32m   1077\u001b[0m         example_inputs,\n\u001b[0;32m   1078\u001b[0m         var_lookup_fn,\n\u001b[0;32m   1079\u001b[0m         strict,\n\u001b[0;32m   1080\u001b[0m         _force_outplace,\n\u001b[0;32m   1081\u001b[0m         argument_names,\n\u001b[0;32m   1082\u001b[0m         _store_inputs,\n\u001b[0;32m   1083\u001b[0m     )\n\u001b[0;32m   1085\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\timm\\models\\vision_transformer.py:760\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 760\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[0;32m    761\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\timm\\models\\vision_transformer.py:737\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 737\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m    738\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_embed(x)\n\u001b[0;32m    739\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_drop(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\timm\\layers\\patch_embed.py:103\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    101\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    102\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[1;32m--> 103\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[0;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "# 使用 TorchScript 將模型保存為 .pt 文件\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example_input)\n",
    "torch.jit.save(traced_script_module, 'deit_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf5782-c7f9-4c31-887f-64efa459dbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
