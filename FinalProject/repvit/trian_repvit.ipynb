{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7af119-40a1-4b24-8b7e-8d9c47a0fe45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料增強與標準化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d46555e-52ed-41f0-9d03-725ae3688493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加載數據\n",
    "train_dataset = datasets.ImageFolder(root='../dataloader_c23/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='../dataloader_c23/validation', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataloader_c23/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e129f28-6706-4096-b016-5a295e64fb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n"
     ]
    }
   ],
   "source": [
    "from repvit import repvit_m1_0\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "# 加載預訓練的 MobileNetV3 大模型\n",
    "model = repvit_m1_0(num_classes=2)\n",
    "checkpoint = torch.load('repvit_m1_0_distill_300e.pth', map_location=device)\n",
    "\n",
    "# 刪除分類層權重\n",
    "pre_dict = {k: v for k, v in checkpoint.items() if k in model.state_dict() and model.state_dict()[k].numel() == v.numel()}\n",
    "missing_keys, unexpected_keys = model.load_state_dict(pre_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79eb62a-610b-49d0-99c4-5ac1b12ce1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "def train(epoch, epochs, model, train_loader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    \n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # 確保數據在正確的設備上\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # 模型輸出\n",
    "        loss = loss_function(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 計算準確率\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    running_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca9b6ea-9961-44c5-91a5-0eda8dd41693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 驗證函數\n",
    "def validate(epoch, epochs, model, validate_loader, loss_function, device):\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_num = len(validate_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            outputs = model(val_images)\n",
    "            loss = loss_function(outputs, val_labels)\n",
    "            val_loss += loss.item() * val_images.size(0)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "    \n",
    "    val_loss /= val_num\n",
    "    val_accurate = acc / val_num\n",
    "    return val_loss, val_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e7c34d-4057-4dfc-8502-dd4518459bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/25] loss:0.594: 100%|██████████| 282/282 [11:00<00:00,  2.34s/it]\n",
      "valid epoch[1/25]: 100%|██████████| 55/55 [00:21<00:00,  2.60it/s]\n",
      "[epoch 1] train_loss: 0.656  train_accuracy: 61.035\n",
      "[epoch 1] val_loss: 0.714  val_accuracy: 0.607\n",
      "Training_Time: 682.05 seconds\n",
      "train epoch[2/25] loss:0.614: 100%|██████████| 282/282 [10:52<00:00,  2.31s/it]\n",
      "valid epoch[2/25]: 100%|██████████| 55/55 [00:22<00:00,  2.46it/s]\n",
      "[epoch 2] train_loss: 0.595  train_accuracy: 67.412\n",
      "[epoch 2] val_loss: 0.639  val_accuracy: 0.639\n",
      "Training_Time: 675.25 seconds\n",
      "train epoch[3/25] loss:0.506: 100%|██████████| 282/282 [11:24<00:00,  2.43s/it]\n",
      "valid epoch[3/25]: 100%|██████████| 55/55 [00:22<00:00,  2.42it/s]\n",
      "[epoch 3] train_loss: 0.502  train_accuracy: 74.990\n",
      "[epoch 3] val_loss: 0.663  val_accuracy: 0.677\n",
      "Training_Time: 707.74 seconds\n",
      "train epoch[4/25] loss:0.363: 100%|██████████| 282/282 [10:51<00:00,  2.31s/it]\n",
      "valid epoch[4/25]: 100%|██████████| 55/55 [00:20<00:00,  2.72it/s]\n",
      "[epoch 4] train_loss: 0.390  train_accuracy: 82.239\n",
      "[epoch 4] val_loss: 0.706  val_accuracy: 0.693\n",
      "Training_Time: 671.86 seconds\n",
      "train epoch[5/25] loss:0.401: 100%|██████████| 282/282 [10:29<00:00,  2.23s/it]\n",
      "valid epoch[5/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 5] train_loss: 0.281  train_accuracy: 87.961\n",
      "[epoch 5] val_loss: 0.791  val_accuracy: 0.697\n",
      "Training_Time: 649.72 seconds\n",
      "train epoch[6/25] loss:0.201: 100%|██████████| 282/282 [10:29<00:00,  2.23s/it]\n",
      "valid epoch[6/25]: 100%|██████████| 55/55 [00:20<00:00,  2.74it/s]\n",
      "[epoch 6] train_loss: 0.187  train_accuracy: 92.456\n",
      "[epoch 6] val_loss: 0.966  val_accuracy: 0.691\n",
      "Training_Time: 649.23 seconds\n",
      "train epoch[7/25] loss:0.227: 100%|██████████| 282/282 [10:29<00:00,  2.23s/it]\n",
      "valid epoch[7/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 7] train_loss: 0.125  train_accuracy: 95.235\n",
      "[epoch 7] val_loss: 1.111  val_accuracy: 0.694\n",
      "Training_Time: 649.41 seconds\n",
      "train epoch[8/25] loss:0.077: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[8/25]: 100%|██████████| 55/55 [00:19<00:00,  2.75it/s]\n",
      "[epoch 8] train_loss: 0.094  train_accuracy: 96.501\n",
      "[epoch 8] val_loss: 1.316  val_accuracy: 0.693\n",
      "Training_Time: 648.84 seconds\n",
      "train epoch[9/25] loss:0.162: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[9/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 9] train_loss: 0.070  train_accuracy: 97.535\n",
      "[epoch 9] val_loss: 1.468  val_accuracy: 0.679\n",
      "Training_Time: 649.31 seconds\n",
      "train epoch[10/25] loss:0.067: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[10/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 10] train_loss: 0.060  train_accuracy: 97.932\n",
      "[epoch 10] val_loss: 1.680  val_accuracy: 0.690\n",
      "Training_Time: 649.04 seconds\n",
      "train epoch[11/25] loss:0.080: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[11/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 11] train_loss: 0.054  train_accuracy: 98.064\n",
      "[epoch 11] val_loss: 1.744  val_accuracy: 0.683\n",
      "Training_Time: 649.04 seconds\n",
      "train epoch[12/25] loss:0.045: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[12/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 12] train_loss: 0.047  train_accuracy: 98.310\n",
      "[epoch 12] val_loss: 1.748  val_accuracy: 0.690\n",
      "Training_Time: 649.37 seconds\n",
      "train epoch[13/25] loss:0.013: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[13/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 13] train_loss: 0.043  train_accuracy: 98.486\n",
      "[epoch 13] val_loss: 1.944  val_accuracy: 0.674\n",
      "Training_Time: 649.04 seconds\n",
      "train epoch[14/25] loss:0.024: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[14/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 14] train_loss: 0.041  train_accuracy: 98.574\n",
      "[epoch 14] val_loss: 1.476  val_accuracy: 0.697\n",
      "Training_Time: 648.79 seconds\n",
      "train epoch[15/25] loss:0.021: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[15/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 15] train_loss: 0.038  train_accuracy: 98.708\n",
      "[epoch 15] val_loss: 1.874  val_accuracy: 0.691\n",
      "Training_Time: 648.67 seconds\n",
      "train epoch[16/25] loss:0.027: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[16/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 16] train_loss: 0.033  train_accuracy: 98.940\n",
      "[epoch 16] val_loss: 1.788  val_accuracy: 0.705\n",
      "Training_Time: 649.02 seconds\n",
      "train epoch[17/25] loss:0.038: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[17/25]: 100%|██████████| 55/55 [00:20<00:00,  2.72it/s]\n",
      "[epoch 17] train_loss: 0.032  train_accuracy: 98.944\n",
      "[epoch 17] val_loss: 1.712  val_accuracy: 0.697\n",
      "Training_Time: 648.67 seconds\n",
      "train epoch[18/25] loss:0.016: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[18/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 18] train_loss: 0.034  train_accuracy: 98.843\n",
      "[epoch 18] val_loss: 1.828  val_accuracy: 0.691\n",
      "Training_Time: 648.60 seconds\n",
      "train epoch[19/25] loss:0.061: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[19/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 19] train_loss: 0.031  train_accuracy: 98.949\n",
      "[epoch 19] val_loss: 1.655  val_accuracy: 0.701\n",
      "Training_Time: 648.93 seconds\n",
      "train epoch[20/25] loss:0.057: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[20/25]: 100%|██████████| 55/55 [00:20<00:00,  2.74it/s]\n",
      "[epoch 20] train_loss: 0.030  train_accuracy: 99.019\n",
      "[epoch 20] val_loss: 1.804  val_accuracy: 0.691\n",
      "Training_Time: 648.84 seconds\n",
      "train epoch[21/25] loss:0.150: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[21/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 21] train_loss: 0.032  train_accuracy: 98.965\n",
      "[epoch 21] val_loss: 1.750  val_accuracy: 0.702\n",
      "Training_Time: 648.86 seconds\n",
      "train epoch[22/25] loss:0.038: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[22/25]: 100%|██████████| 55/55 [00:20<00:00,  2.74it/s]\n",
      "[epoch 22] train_loss: 0.031  train_accuracy: 98.981\n",
      "[epoch 22] val_loss: 1.789  val_accuracy: 0.698\n",
      "Training_Time: 648.89 seconds\n",
      "train epoch[23/25] loss:0.031: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[23/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 23] train_loss: 0.027  train_accuracy: 99.138\n",
      "[epoch 23] val_loss: 1.940  val_accuracy: 0.689\n",
      "Training_Time: 648.40 seconds\n",
      "train epoch[24/25] loss:0.004: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[24/25]: 100%|██████████| 55/55 [00:20<00:00,  2.75it/s]\n",
      "[epoch 24] train_loss: 0.025  train_accuracy: 99.179\n",
      "[epoch 24] val_loss: 1.901  val_accuracy: 0.703\n",
      "Training_Time: 648.60 seconds\n",
      "train epoch[25/25] loss:0.011: 100%|██████████| 282/282 [10:28<00:00,  2.23s/it]\n",
      "valid epoch[25/25]: 100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n",
      "[epoch 25] train_loss: 0.024  train_accuracy: 99.228\n",
      "[epoch 25] val_loss: 2.100  val_accuracy: 0.698\n",
      "Training_Time: 648.73 seconds\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# 訓練和驗證模型\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "save_path = 'best_repvit.pth'\n",
    "t_l, t_a = [], []\n",
    "v_l, v_a = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_accuracy = train(epoch, num_epochs, model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accurate = validate(epoch, num_epochs, model, val_loader, criterion, device)\n",
    "    t_l.append(train_loss)\n",
    "    t_a.append(train_accuracy)\n",
    "    v_l.append(val_loss)\n",
    "    v_a.append(val_accurate)\n",
    "    \n",
    "    print('[epoch %d] train_loss: %.3f  train_accuracy: %.3f' %\n",
    "            (epoch + 1, train_loss, train_accuracy))\n",
    "    print('[epoch %d] val_loss: %.3f  val_accuracy: %.3f' %\n",
    "            (epoch + 1, val_loss, val_accurate))\n",
    "    \n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    end_time = time.time()\n",
    "    print(f'Training_Time: {end_time - start_time:.2f} seconds')\n",
    "    \n",
    "print('訓練完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08680cc5-6341-453e-a191-86aeb2fb6e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6908\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_repvit.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee66c5d-4696-44e8-9565-9a2aad94ebe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metrics_to_file(t_l, t_a, v_l, v_a, filename='metrics.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Train Loss:\\n\")\n",
    "        for item in t_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Train Accuracy:\\n\")\n",
    "        for item in t_a:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Loss:\\n\")\n",
    "        for item in v_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Accuracy:\\n\")\n",
    "        for item in v_a:\n",
    "            file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8cc10f-0bb0-440a-a248-afdd275121dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 假設 t_l, t_a, v_l, v_a 已經被填充\n",
    "filename = 'repvit.txt'\n",
    "save_metrics_to_file(t_l, t_a, v_l, v_a, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be463812-0456-488b-8574-eb4ebedc11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n",
      "Test Acc of Celeb DF V2: 0.7211\n"
     ]
    }
   ],
   "source": [
    "from repvit import repvit_m1_0\n",
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "import sys\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {} device.\".format(device))\n",
    "model = repvit_m1_0(num_classes=2)\n",
    "test_celeb_dataset = datasets.ImageFolder(root='../archive/extracted_frames', transform=transform)\n",
    "celeb_loader = DataLoader(test_celeb_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_repvit.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in celeb_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc of Celeb DF V2: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "901abf05-1fa4-44d2-aeba-97b4d6b92c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用 TorchScript 將模型保存為 .pt 文件\n",
    "import torch\n",
    "\n",
    "# 加載預訓練的 MobileNetV3 大模型\n",
    "model = repvit_m1_0(num_classes=2)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load('best_repvit.pth'))\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example_input)\n",
    "torch.jit.save(traced_script_module, 'repvit_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec931724-c3ad-4f85-be5c-635831000d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
