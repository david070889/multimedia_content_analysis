{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf74bbd-82bd-444d-86aa-9be5172ef5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料增強與標準化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c56a81-864a-42a9-a499-c87ac446501d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加載數據\n",
    "train_dataset = datasets.ImageFolder(root='../dataloader_c23/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root='../dataloader_c23/validation', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataloader_c23/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11130ffe-b414-487e-a919-3c28303c7bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device.\n"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import timm\n",
    "\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "# 加載預訓練的 repvgg 模型\n",
    "model = timm.create_model(\"hf_hub:timm/repvgg_a0.rvgg_in1k\", pretrained=True, num_classes=2)\n",
    "\n",
    "\n",
    "# # 刪除分類層權重\n",
    "# pre_dict = {k: v for k, v in checkpoint.items() if k in model.state_dict() and model.state_dict()[k].numel() == v.numel()}\n",
    "# missing_keys, unexpected_keys = model.load_state_dict(pre_dict, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6643fe-de8a-44e1-b80c-d3a88ab42468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "def train(epoch, epochs, model, train_loader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    \n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # 確保數據在正確的設備上\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)  # 模型輸出\n",
    "        loss = loss_function(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 計算準確率\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    running_loss = running_loss / train_steps\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a543744-3f68-441e-9592-4fd0cba71d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 驗證函數\n",
    "def validate(epoch, epochs, model, validate_loader, loss_function, device):\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_num = len(validate_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            outputs = model(val_images)\n",
    "            loss = loss_function(outputs, val_labels)\n",
    "            val_loss += loss.item() * val_images.size(0)\n",
    "\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "    \n",
    "    val_loss /= val_num\n",
    "    val_accurate = acc / val_num\n",
    "    return val_loss, val_accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5915323-b5e1-4fff-9101-dc6740608949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch[1/25] loss:0.219: 100%|██████████| 282/282 [01:26<00:00,  3.25it/s]\n",
      "valid epoch[1/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 1] train_loss: 0.341  train_accuracy: 84.162\n",
      "[epoch 1] val_loss: 0.394  val_accuracy: 0.844\n",
      "Training_Time: 106.72 seconds\n",
      "train epoch[2/25] loss:0.145: 100%|██████████| 282/282 [01:25<00:00,  3.31it/s]\n",
      "valid epoch[2/25]: 100%|██████████| 55/55 [00:20<00:00,  2.67it/s]\n",
      "[epoch 2] train_loss: 0.170  train_accuracy: 93.200\n",
      "[epoch 2] val_loss: 0.477  val_accuracy: 0.830\n",
      "Training_Time: 105.75 seconds\n",
      "train epoch[3/25] loss:0.094: 100%|██████████| 282/282 [01:24<00:00,  3.32it/s]\n",
      "valid epoch[3/25]: 100%|██████████| 55/55 [00:19<00:00,  2.86it/s]\n",
      "[epoch 3] train_loss: 0.115  train_accuracy: 95.511\n",
      "[epoch 3] val_loss: 1.037  val_accuracy: 0.750\n",
      "Training_Time: 104.10 seconds\n",
      "train epoch[4/25] loss:0.022: 100%|██████████| 282/282 [01:28<00:00,  3.19it/s]\n",
      "valid epoch[4/25]: 100%|██████████| 55/55 [00:20<00:00,  2.73it/s]\n",
      "[epoch 4] train_loss: 0.087  train_accuracy: 96.647\n",
      "[epoch 4] val_loss: 0.485  val_accuracy: 0.853\n",
      "Training_Time: 108.76 seconds\n",
      "train epoch[5/25] loss:0.040: 100%|██████████| 282/282 [01:28<00:00,  3.17it/s]\n",
      "valid epoch[5/25]: 100%|██████████| 55/55 [00:20<00:00,  2.72it/s]\n",
      "[epoch 5] train_loss: 0.066  train_accuracy: 97.465\n",
      "[epoch 5] val_loss: 0.557  val_accuracy: 0.863\n",
      "Training_Time: 109.17 seconds\n",
      "train epoch[6/25] loss:0.051: 100%|██████████| 282/282 [01:30<00:00,  3.10it/s]\n",
      "valid epoch[6/25]: 100%|██████████| 55/55 [00:20<00:00,  2.74it/s]\n",
      "[epoch 6] train_loss: 0.054  train_accuracy: 97.961\n",
      "[epoch 6] val_loss: 0.552  val_accuracy: 0.867\n",
      "Training_Time: 111.03 seconds\n",
      "train epoch[7/25] loss:0.019: 100%|██████████| 282/282 [01:31<00:00,  3.07it/s]\n",
      "valid epoch[7/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 7] train_loss: 0.047  train_accuracy: 98.249\n",
      "[epoch 7] val_loss: 0.574  val_accuracy: 0.860\n",
      "Training_Time: 111.82 seconds\n",
      "train epoch[8/25] loss:0.013: 100%|██████████| 282/282 [01:31<00:00,  3.08it/s]\n",
      "valid epoch[8/25]: 100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n",
      "[epoch 8] train_loss: 0.039  train_accuracy: 98.514\n",
      "[epoch 8] val_loss: 0.521  val_accuracy: 0.871\n",
      "Training_Time: 111.99 seconds\n",
      "train epoch[9/25] loss:0.041: 100%|██████████| 282/282 [01:29<00:00,  3.17it/s]\n",
      "valid epoch[9/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 9] train_loss: 0.033  train_accuracy: 98.761\n",
      "[epoch 9] val_loss: 0.662  val_accuracy: 0.865\n",
      "Training_Time: 108.93 seconds\n",
      "train epoch[10/25] loss:0.017: 100%|██████████| 282/282 [01:28<00:00,  3.17it/s]\n",
      "valid epoch[10/25]: 100%|██████████| 55/55 [00:19<00:00,  2.76it/s]\n",
      "[epoch 10] train_loss: 0.036  train_accuracy: 98.635\n",
      "[epoch 10] val_loss: 0.643  val_accuracy: 0.859\n",
      "Training_Time: 108.79 seconds\n",
      "train epoch[11/25] loss:0.057: 100%|██████████| 282/282 [01:27<00:00,  3.21it/s]\n",
      "valid epoch[11/25]: 100%|██████████| 55/55 [00:19<00:00,  2.75it/s]\n",
      "[epoch 11] train_loss: 0.029  train_accuracy: 98.935\n",
      "[epoch 11] val_loss: 0.598  val_accuracy: 0.880\n",
      "Training_Time: 107.96 seconds\n",
      "train epoch[12/25] loss:0.033: 100%|██████████| 282/282 [01:29<00:00,  3.14it/s]\n",
      "valid epoch[12/25]: 100%|██████████| 55/55 [00:21<00:00,  2.58it/s]\n",
      "[epoch 12] train_loss: 0.029  train_accuracy: 98.925\n",
      "[epoch 12] val_loss: 0.513  val_accuracy: 0.878\n",
      "Training_Time: 111.22 seconds\n",
      "train epoch[13/25] loss:0.040: 100%|██████████| 282/282 [01:26<00:00,  3.25it/s]\n",
      "valid epoch[13/25]: 100%|██████████| 55/55 [00:19<00:00,  2.82it/s]\n",
      "[epoch 13] train_loss: 0.023  train_accuracy: 99.164\n",
      "[epoch 13] val_loss: 0.904  val_accuracy: 0.845\n",
      "Training_Time: 106.15 seconds\n",
      "train epoch[14/25] loss:0.038: 100%|██████████| 282/282 [01:26<00:00,  3.25it/s]\n",
      "valid epoch[14/25]: 100%|██████████| 55/55 [00:20<00:00,  2.72it/s]\n",
      "[epoch 14] train_loss: 0.024  train_accuracy: 99.111\n",
      "[epoch 14] val_loss: 0.762  val_accuracy: 0.851\n",
      "Training_Time: 107.07 seconds\n",
      "train epoch[15/25] loss:0.032: 100%|██████████| 282/282 [01:27<00:00,  3.21it/s]\n",
      "valid epoch[15/25]: 100%|██████████| 55/55 [00:19<00:00,  2.87it/s]\n",
      "[epoch 15] train_loss: 0.020  train_accuracy: 99.264\n",
      "[epoch 15] val_loss: 0.676  val_accuracy: 0.870\n",
      "Training_Time: 107.03 seconds\n",
      "train epoch[16/25] loss:0.001: 100%|██████████| 282/282 [01:25<00:00,  3.28it/s]\n",
      "valid epoch[16/25]: 100%|██████████| 55/55 [00:19<00:00,  2.85it/s]\n",
      "[epoch 16] train_loss: 0.023  train_accuracy: 99.176\n",
      "[epoch 16] val_loss: 0.859  val_accuracy: 0.847\n",
      "Training_Time: 105.27 seconds\n",
      "train epoch[17/25] loss:0.005: 100%|██████████| 282/282 [01:25<00:00,  3.30it/s]\n",
      "valid epoch[17/25]: 100%|██████████| 55/55 [00:19<00:00,  2.85it/s]\n",
      "[epoch 17] train_loss: 0.019  train_accuracy: 99.356\n",
      "[epoch 17] val_loss: 0.645  val_accuracy: 0.877\n",
      "Training_Time: 104.73 seconds\n",
      "train epoch[18/25] loss:0.016: 100%|██████████| 282/282 [01:27<00:00,  3.23it/s]\n",
      "valid epoch[18/25]: 100%|██████████| 55/55 [00:19<00:00,  2.80it/s]\n",
      "[epoch 18] train_loss: 0.022  train_accuracy: 99.200\n",
      "[epoch 18] val_loss: 0.606  val_accuracy: 0.876\n",
      "Training_Time: 107.06 seconds\n",
      "train epoch[19/25] loss:0.016: 100%|██████████| 282/282 [01:27<00:00,  3.24it/s]\n",
      "valid epoch[19/25]: 100%|██████████| 55/55 [00:20<00:00,  2.65it/s]\n",
      "[epoch 19] train_loss: 0.017  train_accuracy: 99.406\n",
      "[epoch 19] val_loss: 0.689  val_accuracy: 0.858\n",
      "Training_Time: 107.87 seconds\n",
      "train epoch[20/25] loss:0.001: 100%|██████████| 282/282 [01:27<00:00,  3.21it/s]\n",
      "valid epoch[20/25]: 100%|██████████| 55/55 [00:19<00:00,  2.82it/s]\n",
      "[epoch 20] train_loss: 0.018  train_accuracy: 99.356\n",
      "[epoch 20] val_loss: 1.040  val_accuracy: 0.798\n",
      "Training_Time: 107.28 seconds\n",
      "train epoch[21/25] loss:0.014: 100%|██████████| 282/282 [01:26<00:00,  3.25it/s]\n",
      "valid epoch[21/25]: 100%|██████████| 55/55 [00:19<00:00,  2.80it/s]\n",
      "[epoch 21] train_loss: 0.018  train_accuracy: 99.315\n",
      "[epoch 21] val_loss: 0.778  val_accuracy: 0.868\n",
      "Training_Time: 106.48 seconds\n",
      "train epoch[22/25] loss:0.020: 100%|██████████| 282/282 [01:25<00:00,  3.31it/s]\n",
      "valid epoch[22/25]: 100%|██████████| 55/55 [00:19<00:00,  2.87it/s]\n",
      "[epoch 22] train_loss: 0.017  train_accuracy: 99.396\n",
      "[epoch 22] val_loss: 0.788  val_accuracy: 0.852\n",
      "Training_Time: 104.44 seconds\n",
      "train epoch[23/25] loss:0.033: 100%|██████████| 282/282 [01:25<00:00,  3.30it/s]\n",
      "valid epoch[23/25]: 100%|██████████| 55/55 [00:19<00:00,  2.86it/s]\n",
      "[epoch 23] train_loss: 0.015  train_accuracy: 99.494\n",
      "[epoch 23] val_loss: 1.005  val_accuracy: 0.841\n",
      "Training_Time: 104.71 seconds\n",
      "train epoch[24/25] loss:0.005: 100%|██████████| 282/282 [01:25<00:00,  3.30it/s]\n",
      "valid epoch[24/25]: 100%|██████████| 55/55 [00:19<00:00,  2.88it/s]\n",
      "[epoch 24] train_loss: 0.018  train_accuracy: 99.346\n",
      "[epoch 24] val_loss: 0.610  val_accuracy: 0.880\n",
      "Training_Time: 104.68 seconds\n",
      "train epoch[25/25] loss:0.002: 100%|██████████| 282/282 [01:25<00:00,  3.30it/s]\n",
      "valid epoch[25/25]: 100%|██████████| 55/55 [00:19<00:00,  2.87it/s]\n",
      "[epoch 25] train_loss: 0.014  train_accuracy: 99.499\n",
      "[epoch 25] val_loss: 0.604  val_accuracy: 0.886\n",
      "Training_Time: 104.68 seconds\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# 訓練和驗證模型\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "train_steps = len(train_loader)\n",
    "save_path = 'best_repvgg.pth'\n",
    "t_l, t_a = [], []\n",
    "v_l, v_a = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_accuracy = train(epoch, num_epochs, model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accurate = validate(epoch, num_epochs, model, val_loader, criterion, device)\n",
    "    t_l.append(train_loss)\n",
    "    t_a.append(train_accuracy)\n",
    "    v_l.append(val_loss)\n",
    "    v_a.append(val_accurate)\n",
    "    \n",
    "    print('[epoch %d] train_loss: %.3f  train_accuracy: %.3f' %\n",
    "            (epoch + 1, train_loss, train_accuracy))\n",
    "    print('[epoch %d] val_loss: %.3f  val_accuracy: %.3f' %\n",
    "            (epoch + 1, val_loss, val_accurate))\n",
    "    \n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    end_time = time.time()\n",
    "    print(f'Training_Time: {end_time - start_time:.2f} seconds')\n",
    "    \n",
    "print('訓練完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7623dae-e203-4fde-b2a7-b1b01259cfd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.8923\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_repvgg.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c1631c-cc14-40a2-8ffc-75f4cd696dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metrics_to_file(t_l, t_a, v_l, v_a, filename='metrics.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Train Loss:\\n\")\n",
    "        for item in t_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Train Accuracy:\\n\")\n",
    "        for item in t_a:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Loss:\\n\")\n",
    "        for item in v_l:\n",
    "            file.write(f\"{item}\\n\")\n",
    "        \n",
    "        file.write(\"Validation Accuracy:\\n\")\n",
    "        for item in v_a:\n",
    "            file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81751bd-2cd8-4331-a3b8-97af6a63ee45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 假設 t_l, t_a, v_l, v_a 已經被填充\n",
    "filename = 'repvgg.txt'\n",
    "save_metrics_to_file(t_l, t_a, v_l, v_a, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd82f171-a385-4e5c-b69f-3ffbb073b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc of Celeb DF V2: 0.7386\n"
     ]
    }
   ],
   "source": [
    "test_celeb_dataset = datasets.ImageFolder(root='../CelebDF_v2/extracted_frames', transform=transform)\n",
    "celeb_loader = DataLoader(test_celeb_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# 測試模型\n",
    "model.load_state_dict(torch.load('best_repvgg.pth'))\n",
    "model.eval()\n",
    "test_running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in celeb_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = test_running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Acc of Celeb DF V2: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb4f8532-58ef-4554-999f-e567fc52707b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用 TorchScript 將模型保存為 .pt 文件\n",
    "import torch\n",
    "from timm import create_model\n",
    "\n",
    "# 創建模型\n",
    "model = create_model('repvgg_a0', pretrained=False, num_classes=2)\n",
    "model.load_state_dict(torch.load('best_repvgg.pth'))\n",
    "model.eval()\n",
    "\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example_input)\n",
    "torch.jit.save(traced_script_module, 'repvgg_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef210222-5a69-42e3-9e62-27a203e1c660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
